<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Random Thoughts - Deep Learning</title><link href="https://anhlt.github.io/" rel="alternate"></link><link href="https://anhlt.github.io/feeds/deep-learning.atom.xml" rel="self"></link><id>https://anhlt.github.io/</id><updated>2020-06-16T19:18:33+09:00</updated><subtitle>✨ Suy nghĩ vu vơ</subtitle><entry><title>Giải thích bài báo DEtection TRansformer</title><link href="https://anhlt.github.io/End-t-End-transformer-classic-object-detection-vi.html" rel="alternate"></link><published>2020-06-16T19:18:33+09:00</published><updated>2020-06-16T19:18:33+09:00</updated><author><name>h4cker</name></author><id>tag:anhlt.github.io,2020-06-16:/End-t-End-transformer-classic-object-detection-vi.html</id><summary type="html">&lt;p&gt;Giới thiệu bài toán Object Detection cổ điển, từ đó nắm bắt được ý tưởng của các thuật toán Deep Learing phức tạp hơn&lt;/p&gt;</summary><content type="html">&lt;p&gt;Từ trước đến nay bài toán object detection thường dựa vào các thuật toán thiết kế thủ công như Non-maximum Suppession, hay anchor generation để thiết kế mạng network. Bài báo này đưa ra một phương pháp mới mới gọi là "DEtection TRansformer" sử dụng kiến trúc transfomer để giải quyết bài toán object detection.&lt;/p&gt;
&lt;h3 id="mot-so-khai-niem"&gt;Một số khái niệm&lt;/h3&gt;
&lt;h4 id="hungarian-algotithm"&gt;Hungarian Algotithm&lt;/h4&gt;
&lt;h5 id="bai-toan"&gt;Bài toán&lt;/h5&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Một nhà máy có bốn nhân công thực hiện 4 công việc khác nhau trong
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="math"&gt;$$
\begin{array}{llll}
30 &amp;amp; 40 &amp;amp; 50 &amp;amp; 60 \\
70 &amp;amp; 30 &amp;amp; 40 &amp;amp; 70 \\
60 &amp;amp; 50 &amp;amp; 60 &amp;amp; 30 \\
20 &amp;amp; 80 &amp;amp; 50 &amp;amp; 70
\end{array}
$$&lt;/div&gt;
&lt;h3 id="kien-truc-mang-detr"&gt;Kiến trúc mạng DETR&lt;/h3&gt;
&lt;p&gt;&lt;img src="/images/08/network.png" width="1000" title="'DETR'" alt="'DETR'"&gt;&lt;/p&gt;
&lt;p&gt;Kiến trúc mạng DETR gồm 3 thành phần chính&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Backbone network&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Tương tự như Faster RCNN, DETR sử dụng một mạng CNN để thu được &lt;code&gt;convolutional features&lt;/code&gt; của ảnh đầu vào. &lt;/p&gt;
&lt;p&gt;Với mỗi ảnh đầu vào có kích thước&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$x_{\mathrm{img}} \in \mathbb{R}^{3 \times H_{0} \times W_{0}}$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;thu được &lt;code&gt;convolutional features&lt;/code&gt; có kích thước &lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$f \in \mathbb{R}^{C \times H \times W} $$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;trong đó &lt;span class="math"&gt;\(C=2048\)&lt;/span&gt; , &lt;span class="math"&gt;\(H, W=\frac{H_{0}}{32}, \frac{W_{0}}{32}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/rpn/step-1.png" width="400" title="'Fast RCNN'" alt="'Fast RCNN'"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Transformer encoder&lt;/strong&gt;    &lt;/p&gt;
&lt;p&gt;Ở đây, tác giả sử dụng &lt;span class="math"&gt;\(1x1\)&lt;/span&gt; convolution để giảm chiều &lt;code&gt;convolutional features&lt;/code&gt; từ &lt;span class="math"&gt;\(C\)&lt;/span&gt; xuống &lt;span class="math"&gt;\(z_{0} \in \mathbb{R}^{d \times H \times W}\)&lt;/span&gt;. 
Bởi vì &lt;code&gt;encoder&lt;/code&gt; có đầu vào dạng &lt;code&gt;sequence&lt;/code&gt;, tại đây, &lt;code&gt;features&lt;/code&gt; được &lt;code&gt;flatten&lt;/code&gt; thành &lt;span class="math"&gt;\(z_{0} \in \mathbb{R}^{d \times HW}\)&lt;/span&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src="/images/08/step1.png" width="400" title="'Fast RCNN'" alt="'Fast RCNN'"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/08/transformer.png" width="400" title="'Encoder-Decoder' | Hello" alt="'Encoder-Decoder' | Hello"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="loss-function"&gt;Loss Function&lt;/h3&gt;
&lt;p&gt;DETR cho ra output gồm N dự đoán &lt;/p&gt;
&lt;div class="math"&gt;$$y = N \times \left(c_{i} , b_{i}\right)$$&lt;/div&gt;
&lt;p&gt;với &lt;span class="math"&gt;\(c_{i}\)&lt;/span&gt; là xác suất  &lt;/p&gt;
&lt;div class="math"&gt;$$\hat{y} = N  \times \left(c_i , b_i\right)$$&lt;/div&gt;
&lt;div class="math"&gt;$$
\hat{\sigma}=\underset{\sigma \in \mathfrak{S}_{N}}{\arg \min } \sum_{i}^{N} \mathcal{L}_{\mathrm{match}}\left(y_{i}, \hat{y}_{\sigma(i)}\right)
$$&lt;/div&gt;
&lt;h4 id="hungarian-loss"&gt;Hungarian Loss&lt;/h4&gt;
&lt;div class="math"&gt;$$
\mathcal{L}_{\text {Hungarian }}(y, \hat{y})=\sum_{i=1}^{N}\left[-\log \hat{p}_{\hat{\sigma}(i)}\left(c_{i}\right)+\mathbb{1}_{\left\{c_{i} \neq \varnothing\right\}} \mathcal{L}_{\mathrm{box}}\left(b_{i}, \hat{b}_{\hat{\sigma}}(i)\right)\right]
$$&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Deep Learning"></category><category term="vietnamese"></category><category term="explained"></category><category term="object_detection"></category><category term="transfomer"></category></entry><entry><title>Bài toán Object Detection cổ điển</title><link href="https://anhlt.github.io/classic-object-detection-vi.html" rel="alternate"></link><published>2018-01-16T19:18:33+09:00</published><updated>2018-01-16T19:18:33+09:00</updated><author><name>h4cker</name></author><id>tag:anhlt.github.io,2018-01-16:/classic-object-detection-vi.html</id><summary type="html">&lt;p&gt;Giới thiệu bài toán Object Detection cổ điển, từ đó nắm bắt được ý tưởng của các thuật toán Deep Learing phức tạp hơn&lt;/p&gt;</summary><content type="html">&lt;p&gt;Nhiều năm về trước, bài toán object detection thường sử dụng những thuật toán đơn giản, tốc độ tính toán nhanh, nhưng bù lại độ chính xác không tốt như sử dụng deep learning. Mặc dù vậy, để hiểu rõ hơn về ý tưởng của các thuật toán phức tạp hơn, hôm nay mình muốn giới thiệu ý tưởng của 1 thuật toán cổ điển, sử dụng HOG. Mục đích của bài viết này chỉ là giới thiệu về ý tưởng của thuật toán , nên mình sẽ không code bài toán này. &lt;/p&gt;
&lt;h3 id="trich-xuat-thuoc-tinh"&gt;Trích xuất thuộc tính&lt;/h3&gt;
&lt;p&gt;Trích xuất thuộc tính(feature extraction) là một quá trình nhằm biến dữ liệu phức tạp đầu vào thành một cách biểu diễn dữ liệu đơn giản hơn, phù hợp hơn cho các thuật toán học máy. Dữ liệu sau khi xử lý đã được lược bỏ phần dữ liệu dư thừa, giữ lại những dữ liệu có ích cho bài toán cần xử lý.&lt;/p&gt;
&lt;p&gt;Trong bài toán object detection, đầu vào của dữ liệu là hình ảnh , vì thế để đơn giản hơn cho việc tính toán chúng ra sử dụng một số thuật toán để trích xuất như HOG, SIFT. Trong nội dung bài viết này, tôi không đi sâu về các thuật toán trích xuất dữ liệu này.&lt;/p&gt;
&lt;h3 id="histogram-of-oriented-gradients"&gt;Histogram of Oriented Gradients&lt;/h3&gt;
&lt;p&gt;Histogram of Oriented Gradients(HOG) là một thuật toán để trích xuất thuộc tính hình ảnh. Vậy cụ thể HOG có đầu ra như thế nào. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HOG chia hình ảnh đầu vào thành một lưới các ô vuông&lt;/li&gt;
&lt;li&gt;Mỗi ô vuông trích xuất thành một vector hướng của gradient trong cell đó&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img class="right" src="/images/06/hog_01.png" width="200"&gt;&lt;/p&gt;
&lt;p&gt;Trích dẫn một ví dụ về đầu ra của HOG từ trang &lt;a href="http://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html"&gt;scikit-image.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class="right" src="/images/06/hog_02.png" width="800" title="hehehe" alt="hehehe"&gt;&lt;/p&gt;
&lt;p&gt;Từ ví dụ trên ta có thể thấy, trích xuất thuộc tính bằng HOG bảo toàn thông tin về đường viền của đối tượng trong ảnh, làm mất đi các thông tin về màu sắc, giảm độ sắc nét của dữ liệu. &lt;/p&gt;
&lt;p&gt;Thông thường, đầu vào của một hình ảnh có kích thước &lt;span class="math"&gt;\(W x H x 3\)&lt;/span&gt; , đầu ra của HOG là vector 1-D &lt;span class="math"&gt;\(N x 1\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Đã có một bài viết tiếng Việt đề cập khá cụ thể về cách tính HOG feature từ &lt;a href="https://viblo.asia/p/tim-hieu-ve-hoghistogram-of-oriented-gradients-m68Z0wL6KkG"&gt;Viblo&lt;/a&gt;. Các bạn có thể tham khảo thêm&lt;/p&gt;
&lt;h3 id="sliding-window"&gt;Sliding Window&lt;/h3&gt;
&lt;p&gt;Sau khi đã có HOG feature descriptor, ta sẽ sử dụng vào bài toán object detector. Phần này tôi sẽ lược dịch từ trang &lt;a href="https://www.pyimagesearch.com/2014/11/10/histogram-oriented-gradients-object-detection/"&gt;pyimagesearch.com&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Lấy ra số lượng P các hỉnh ảnh chưa đối tượng và trích xuât HOG feature descriptor từ các hình ảnh này&lt;/li&gt;
&lt;li&gt;Lấy ra N các hình ảnh không chưa bất kì một đối tượng nào và trích xuất HOG feature descriptor từ các hình ảnh này. Trong thực tế thì &lt;span class="math"&gt;\(N &amp;gt;&amp;gt; P\)&lt;/span&gt;  &lt;/li&gt;
&lt;li&gt;Huấn luyện mạng SVM trên các HOG feature descriptor trên tập dữ liệu từ bước một và bước 2&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Đối với mỗi hình ảnh trong tập không chứa đối tượng, sử dụng phương pháp sliding window, tại mỗi vị trí cửa sổ tính toán giá trị HOG và sử dụng mô hình SVM đã huấn luyện ở trên để dự đoán kết quả. Nếu mô hình đưa ra kết quả sai, lưu lại giá trị HOG tương ứng tại vị trí cửa sổ đó cùng xác suất được dự đoán&lt;/p&gt;
&lt;p&gt;&lt;img class="right" src="/images/06/sliding_window_example.gif" width="200"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Lấy các kết quả false-positive tìm thấy ở bước 4 , sắp xếp theo giá trị của xác suất và huấn luyện lại mô hình SVM&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Kết thúc&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="loi-ket"&gt;Lời kết&lt;/h3&gt;
&lt;p&gt;Giải quyết bài toán object detection bằng các phương pháp cổ điển có ưu điểm là cần năng lực tính toán thấp, mô hình đơn giản, tốc độ xử lý nhanh. Nhưng trong quá trình xử lý làm mất đi nhiều thông tin giá trị của hình ảnh như màu sắc, độ sắc nét. Dẫn tới độ chính xác không cao.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Deep Learning"></category><category term="vietnamese"></category><category term="explained"></category><category term="object_detection"></category></entry><entry><title>Giải thích về mô hình Faster RCNN - Phần 1: RPN</title><link href="https://anhlt.github.io/rpn-explained-vi.html" rel="alternate"></link><published>2017-10-08T03:27:29+09:00</published><updated>2017-10-09T03:27:29+09:00</updated><author><name>h4cker</name></author><id>tag:anhlt.github.io,2017-10-08:/rpn-explained-vi.html</id><summary type="html">&lt;p&gt;Region Proposal Networks (RPNs)&lt;/p&gt;</summary><content type="html">&lt;h3 id="gioi-thieu-ve-faster-rcnn"&gt;Giới thiệu về Faster RCNN&lt;/h3&gt;
&lt;p&gt;Faster RCNN là một thuật toán để tìm kiếm vị trí của vật thể trong ảnh. Thuật toán này sẽ có đầu ra là những hình hộp, cùng với vật thể bên trong hộp đó là gì. Phiên bản đầu tiên của Faster RCNN là RCNN, với nguyên lý khá đơn giản. &lt;/p&gt;
&lt;p&gt;&lt;a href="/rpn-explained-code-pytorch.html"&gt;Phần 2: Giải thích RCNN bằng Pytorch&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id="rcnn"&gt;RCNN&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Tác giả sử dụng một thuật toán gọi là selective search để đưa ra các bounding boxes, hay còn gọi là region proposals, chứa các vùng có thể có vật thể ở trong. &lt;/li&gt;
&lt;li&gt;Sử dụng các mạng đã được huấn luyện sẵn như Alex-net, VGG-16 để tính toán feed-forward các regions thu được convolutional features của mỗi region, sau đó huấn luyện SVM để xác định được vật thể nào được chứa trong region proposal đó. &lt;/li&gt;
&lt;li&gt;Sử dụng Linear Regression để hiệu chỉnh các giá trị ( vị trí các đỉnh) của region proposer &lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id="fast-rcnn"&gt;Fast RCNN&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Sử dụng các mạng huấn luyện sẵn để feed-forward các region proposals, sẽ tốn nhiều thời gian bởi với mỗi ảnh thuật toán selective search sẽ cho ra hàng nghìn region proposals. &lt;/li&gt;
&lt;li&gt;Tác giả sẽ chỉ feed-forward một lần đối với ảnh gốc, thu được convolutional features của ảnh đó. Ví dụ với một hình ảnh có kích thước &lt;span class="math"&gt;\(600 * 600 * 3\)&lt;/span&gt;, ta sẽ thu được convolutional features với kích thước &lt;span class="math"&gt;\(37 * 37 * 512\)&lt;/span&gt;. Kích thước của features bị giảm nhỏ khoảng 16 lần &lt;span class="math"&gt;\(\frac{600}{37}\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Dựa vào kích thước cùng vị trí của các region proposals đối với ảnh gốc, ta sẽ tính toán được vị trí của region proposal trong convolutional features.&lt;/li&gt;
&lt;li&gt;Sửa dụng giá trị convolutional faetures của region proposal, ta dự đoán được vị trí các đỉnh của bounding box cũng như vật thể nằm trong bounding box là gì.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src="/images/rpn/fast_rcnn.png" width="600" title="'Fast RCNN'" alt="'Fast RCNN'"&gt;&lt;/p&gt;
&lt;p&gt;Source: https://www.slideshare.net/simplyinsimple/detection-52781995.&lt;/p&gt;
&lt;p&gt;Đối với Fast RCNN , do chia sẻ tính toán giữa các region trong ảnh, tốc độ thực thực thi của thuật toán đã được giảm từ 120s mỗi ảnh xuống 2s. Phần tính toán gây ra nghẽn chính là phần đưa ra các region proposal đầu vào, chỉ có thể thực thi tuần tự trên CPU. Faster RCNN giải quyết vấn đề này bằng cách sử dụng DNN để tính toán các region proposals này.&lt;/p&gt;
&lt;h3 id="rpn"&gt;RPN&lt;/h3&gt;
&lt;p&gt;RPN giải quyết các vấn đề trên bằng cách huấn luyện mạng neural network để đảm nhận thay vai trò của các thuật toán như selective search vốn rất chậm chạp.&lt;/p&gt;
&lt;p&gt;Một Region Proposal Network nhận đầu vào là ảnh với kích thước bất kì và cho đầu ra là region proposal (tập vị trí của các hình chữ nhật có thể chứa vật thể), cùng với xác suất chứa vật thể của hình chữ nhật tương ứng.&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id="cau-truc"&gt;Cấu trúc&lt;/h4&gt;
&lt;p&gt;Cách hoạt động RPN có 2 bước chính&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Feed-forward ảnh qua DNN thu được convolutional features.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Trong bài báo gốc, tác giả đã nhắc đến nhiều các mạng Convolution Network có sẵn như VGG-16, ZFNet, để dễ dàng cho việc giải thích, chúng ta sẽ lấy ví dụ ở đây là mạng VGG-16. &lt;/p&gt;
&lt;p&gt;Mạng VGG-16 chứa 13   convolutions layer kích thước &lt;span class="math"&gt;\(3 \times 3\)&lt;/span&gt; cùng với 5  max pooling layer kích thước &lt;span class="math"&gt;\(2 \times 2\)&lt;/span&gt;. Khi đầu vào là một ảnh có kích thước &lt;span class="math"&gt;\(3 \times W \times H\)&lt;/span&gt; , đầu ra sẽ nhận được &lt;span class="math"&gt;\(3 \times W^{'} \times H^{'}\)&lt;/span&gt; với &lt;span class="math"&gt;\(W^{'} = \frac{W}{16}\)&lt;/span&gt; &lt;span class="math"&gt;\(H^{'} = \frac{H}{16}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/rpn/step-1.png" width="600" title="'Fast RCNN'" alt="'Fast RCNN'"&gt;&lt;/p&gt;
&lt;p&gt;Source: https://www.quora.com/How-does-the-region-proposal-network-RPN-in-Faster-R-CNN-work.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sử dụng một cửa sổ trượt lên convolutional features .&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/rpn/rpn.png" width="600" title="'RPN'" alt="'RPN'"&gt;&lt;/p&gt;
&lt;p&gt;Để tạo ra region proposals, chúng ta sử dụng một network hay còn gọi là cửa sổ trượt (sliding-window) kích thước &lt;span class="math"&gt;\(n \times n\)&lt;/span&gt; trượt trên convolutional features. Đầu ra của network này là đầu vào của 2 fully-connected layer dự đoán vị trí của regions (box-regression layer), cũng như xác suất chứa object(box-classification) của hộp ấy. Tại mỗi vị trí của cửa sổ trượt chúng ta dự đoán đồng thời nhiều nhiều region proposal cùng một lúc, với &lt;span class="math"&gt;\(k\)&lt;/span&gt; là số proposal tương ứng với mỗi vị trí. Vậy &lt;span class="math"&gt;\(reg\)&lt;/span&gt; layer có &lt;span class="math"&gt;\(4k\)&lt;/span&gt; đầu ra dự đoán vị trí của &lt;span class="math"&gt;\(k\)&lt;/span&gt; proposal,  &lt;span class="math"&gt;\(cls\)&lt;/span&gt; layer chứa &lt;span class="math"&gt;\(2k\)&lt;/span&gt; đầu ra dự đoán xác suất chứa vật thể của proposal.&lt;/p&gt;
&lt;p&gt;Source: https://www.quora.com/How-does-the-region-proposal-network-RPN-in-Faster-R-CNN-work.&lt;/p&gt;
&lt;p&gt;Tại sao phải tạo ra những anchors này. Theo cách hiểu của bản thân tôi thì, trong bài toán xác định vị trí vật thể, số lượng đầu ra của mỗi ảnh là khác nhau. Ví dụ một bức ảnh có thể có 2 vật thể, một bức ảnh khác có 4 vật thể. Vì số lượng output là không cố định ta phải dựa vào các anchor để cố định hóa số lượng output này. &lt;/p&gt;
&lt;p&gt;Đối với mỗi bức ảnh, ta đều sinh ra các anchors tương ứng phụ thuộc vào kích cỡ của ảnh đó, bằng cách tính giá trị overlap của anchors với ground truth boxes, ta có thể xác định được anchors đó là positive hay negative. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;RPN (
(features): Sequential (
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU (inplace)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU (inplace)
    (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU (inplace)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU (inplace)
    (9): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU (inplace)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU (inplace)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU (inplace)
    (16): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU (inplace)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU (inplace)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU (inplace)
    (23): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU (inplace)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU (inplace)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU (inplace)
    (30): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
)
(conv1): Conv2d (
    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu): ReLU (inplace)
)
(score_conv): Conv2d (
    (conv): Conv2d(512, 18, kernel_size=(1, 1), stride=(1, 1))
)
(bbox_conv): Conv2d (
    (conv): Conv2d(512, 36, kernel_size=(1, 1), stride=(1, 1)))
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id="anchors"&gt;Anchors&lt;/h4&gt;
&lt;p&gt;&lt;img src="/images/rpn/anchors.png" width="600" title="'RPN'" alt="'RPN'"&gt;&lt;/p&gt;
&lt;p&gt;Sau khi đã có đầu ra của các region proposal, chúng ta sẽ tìm hiểu về khái niệm anchors. Tại mỗi vị trí của sliding window trên convolutional features, chúng ta tạo ra &lt;span class="math"&gt;\(k\)&lt;/span&gt; anchors tương ứng ở hình ảnh gốc. Trong bài báo, tác giả sử dụng 1 hình vuông, 2 hình chữ nhật với tỉ lệ chiều rộng, chiều dài là 1-2, 2-1, cùng với 3 kích cỡ khác nhau, như vậy &lt;span class="math"&gt;\(k = 3 \times 3 = 9\)&lt;/span&gt;. &lt;/p&gt;
&lt;p&gt;Các anchors này sẽ được gán mác là positive hoặc negative dựa vào diện tích overlap với ground truth box theo luật như sau.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Các anchor được phân loại là positive nếu&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Là anchor có  tỉ lệ diện tích chồng chéo trên diện tích chồng chập (Intersection-over-
Union - viết tắt IoU) overlap lớn nhất với một ground truth box.&lt;/li&gt;
&lt;li&gt;Là anchor có  tỉ lệ IoU với một ground truth lớn hơn 0.7&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Các anchor được phân noại là negative nếu có giá trị IoU bé hơn 0.3&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Các anchor không thỏa mãn 2 điều kiện nêu trên thì bỏ qua. Không được đánh giá trong quá trình training object.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Tại sao phải tạo ra những anchors này&lt;/strong&gt;. Câu trả lời gồm 2 nguyên nhân chính&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Dựa phân loại của anchor, để dự đoán xác suất chứa vật thể của các region proposal&lt;/li&gt;
&lt;li&gt;Dựa vào khoảng cách từ anchor đến ground truth box, để dự đoán vị trí của bounding box. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Từ đây ta xác định được tiêu đầu ra của &lt;em&gt;box-regression layer&lt;/em&gt; và &lt;em&gt;box-classification&lt;/em&gt; được nhắc tới ở phần cấu trúc mạng RPN. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Box-classification dự đoán xác suất chứa vật thể của &lt;span class="math"&gt;\(k\)&lt;/span&gt; region proposal, tương ứng với &lt;span class="math"&gt;\(k\)&lt;/span&gt; anchor tại từng vị trí của sliding-window.&lt;/li&gt;
&lt;li&gt;Box-regression dự đoán khoảng cách tư anchor đến ground truth box tương ứng.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="loss-function"&gt;Loss function&lt;/h3&gt;
&lt;p&gt;Loss function sẽ được định nghĩa theo công thức sau &lt;/p&gt;
&lt;div class="math"&gt;$$
L(\{ p_i \}, \{ t_i \}) = \frac{1}{N_{cls}} \sum_{i} L_{cls} (p_i, p_i^{*}) + \lambda \frac{1}{N_{reg}} \sum_{i} p_i^{*} L_{reg}(t_i, t_i^{*})
$$&lt;/div&gt;
&lt;p&gt;
Với &lt;span class="math"&gt;\(i\)&lt;/span&gt; là index của anchor trong mini-batch và &lt;span class="math"&gt;\(p_i\)&lt;/span&gt; là xác suất dự đoán của anchor &lt;span class="math"&gt;\(i\)&lt;/span&gt; là một đối tượng. Giá trị nhãn ground-truth &lt;span class="math"&gt;\(p_i^{*}\)&lt;/span&gt; là một nếu anchor là positive, và là không khi anchor là negative.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(t_i\)&lt;/span&gt;  là một vector 4 chiều biểu diễn giá trị tọa độ của bounding box đã được dự đoán. &lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(t_i^{*}\)&lt;/span&gt; là vector 4 chiều biểu diễn giá trị tọa độ của ground-truth box tương ứng với positive anchor.&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(L_{cls}\)&lt;/span&gt; là log loss của 2 class (object và non-object) &lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(L_{reg}\)&lt;/span&gt; dùng SmoothL1Loss&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="cong-thuc-tinh-smooth-l1"&gt;Công thức tính Smooth L1&lt;/h4&gt;
&lt;div class="math"&gt;$$
loss(x, y) = \sum \begin{cases} 
        0.5 * (x_i - y_i)^2, if |x_i - y_i| &amp;lt; 1 \\  
        |x_i - y_i| - 0.5,   otherwise   
        \end{cases} \quad
$$&lt;/div&gt;
&lt;figure class='code'&gt;
&lt;figcaption&gt;&lt;span class="liquid-tags-code-title"&gt;anchor_target_layer.py&lt;/span&gt;&lt;span class="liquid-tags-code-lines"&gt;[Lines 208-227]&lt;/span&gt;&lt;a href='/code/rpn/anchor_target_layer.py'&gt;download&lt;/a&gt;&lt;/figcaption&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;    &lt;span class="n"&gt;bbox_targets&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_compute_targets&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;anchors&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gt_boxes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;argmax_overlaps&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:])&lt;/span&gt;

    &lt;span class="n"&gt;bbox_inside_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inds_inside&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;bbox_inside_weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cfg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TRAIN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RPN_BBOX_INSIDE_WEIGHTS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;bbox_outside_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inds_inside&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;cfg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TRAIN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RPN_POSITIVE_WEIGHT&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c1"&gt;# uniform weighting of examples (given non-uniform sampling)&lt;/span&gt;
        &lt;span class="n"&gt;num_examples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;positive_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_examples&lt;/span&gt;
        &lt;span class="n"&gt;negative_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_examples&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;cfg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TRAIN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RPN_POSITIVE_WEIGHT&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;
                &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cfg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TRAIN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RPN_POSITIVE_WEIGHT&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;positive_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cfg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TRAIN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RPN_POSITIVE_WEIGHT&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;
                            &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;negative_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;cfg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TRAIN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RPN_POSITIVE_WEIGHT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;
                            &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;bbox_outside_weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;positive_weights&lt;/span&gt;
    &lt;span class="n"&gt;bbox_outside_weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;negative_weights&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;bbox_inside_weights&lt;/code&gt; tương ứng với giá trị nhãn &lt;span class="math"&gt;\(p_{i}^{*}\)&lt;/span&gt; có giá trị bằng một khi anchor tương ứng là positive anchors
&lt;code&gt;bbox_outside_weights&lt;/code&gt;  là hệ số để cân bằng giữa positive anchor và negative anchors  và đã nhân với giá trị  &lt;span class="math"&gt;\(\frac{1}{N_{reg}}\)&lt;/span&gt; . Trong cấu hình đưa ra bởi tác giả thì &lt;code&gt;TRAIN.RPN_POSITIVE_WEIGHT = -1&lt;/code&gt;. Lúc này giá trị hệ số là bằng nhau.
Định ngĩa của loss function&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nx"&gt;layer&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rpn_loss_bbox&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;type&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;SmoothL1Loss&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;bottom&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rpn_bbox_pred&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;bottom&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rpn_bbox_targets&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;bottom&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="nx"&gt;rpn_bbox_inside_weights&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;bottom&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="nx"&gt;rpn_bbox_outside_weights&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;top&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rpn_loss_bbox&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;loss_weight&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nx"&gt;smooth_l1_loss_param&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m m-Double"&gt;3.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id="loi-ket"&gt;Lời kết&lt;/h3&gt;
&lt;p&gt;Tôi đã gặp khó khăn rất nhiều khi tìm hiểu lý thuyết cũng như cách huấn luyện mạng Faster RCNN. Bài viết này nhằm chia sẻ những điều tôi đã học được cũng như cách tôi đã viết lại Faster RCNN bằng pytorch như thế nào. 
Bạn có thể tham khảo tại github của tôi. &lt;a href="https://github.com/anhlt/faster_rcnn"&gt;pytorch faster rcnn&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="trich-dan"&gt;Trích Dẫn&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.quora.com/How-does-RPN-work-on-the-Faster-R-CNN?no_redirect=1" title="How-does-RPN-work-on-the-Faster-R-CNN"&gt;"How-does-RPN-work-on-the-Faster-R-CNN"&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Deep Learning"></category><category term="RPN"></category><category term="faster_rcnn"></category><category term="vietnamese"></category><category term="explained"></category></entry></feed>